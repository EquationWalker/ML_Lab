{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "from torch.utils import data\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from visdom import Visdom\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "import numpy as np\n",
    "viz = Visdom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_fashion_mnist(batch_size, train_rate=0.8, resize=None):\n",
    "    trans = [transforms.ToTensor()]\n",
    "    if resize:\n",
    "        trans.insert(0, transforms.Resize(resize))\n",
    "    trans = transforms.Compose(trans)\n",
    "    mnist_train = datasets.FashionMNIST(root='../data', train=True,\n",
    "                                        transform=trans, download=False)\n",
    "    mnist_test = datasets.FashionMNIST(root='../data', train=False,\n",
    "                                       transform=trans, download=False)\n",
    "\n",
    "    train_size = int(train_rate* len(mnist_train))\n",
    "    val_size = len(mnist_train) - train_size\n",
    "    train_dataset, val_dataset = data.random_split(\n",
    "        mnist_train, [train_size, val_size])\n",
    "\n",
    "    return (data.DataLoader(train_dataset, batch_size, shuffle=True),\n",
    "            data.DataLoader(val_dataset, batch_size, shuffle=False),\n",
    "            mnist_test,\n",
    "            mnist_train.classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 展示一批数据\n",
    "data_iter, _, _, classes = load_data_fashion_mnist(64)\n",
    "batch_data = next(iter(data_iter))\n",
    "for i in range(2):\n",
    "    batch_data[i] = batch_data[i].squeeze().numpy()\n",
    "titles = [classes[i] for i in batch_data[1]]\n",
    "fig = make_subplots(rows=4, cols=16, subplot_titles=titles)\n",
    "for r in range(4):\n",
    "    for c in range(16):\n",
    "        fig.add_trace(go.Heatmap(z=batch_data[0][r*4+c]), row=r+1, col=c+1)\n",
    "\n",
    "fig.update_layout(title_text=\"FashionMNIST\")\n",
    "fig.update_xaxes(showticklabels=False)\n",
    "fig.update_yaxes(showticklabels=False,autorange=\"reversed\")\n",
    "viz.plotlyplot(fig, win='datashow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义网络\n",
    "class Reshape(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(-1, 1, 28, 28)\n",
    "net = nn.Sequential(Reshape(), nn.Conv2d(1, 6, kernel_size=5,\n",
    "                                                 padding=2), nn.Sigmoid(),\n",
    "                            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "                            nn.Conv2d(6, 16, kernel_size=5), nn.Sigmoid(),\n",
    "                            nn.AvgPool2d(\n",
    "                                kernel_size=2, stride=2), nn.Flatten(),\n",
    "                            nn.Linear(16 * 5 * 5, 120), nn.Sigmoid(),\n",
    "                            nn.Linear(120, 84), nn.Sigmoid(), nn.Linear(84, 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 每一个训练epoch\n",
    "def train_epoch(model, train_loader, optimizer, loss_fn, epoch):\n",
    "    size = len(train_loader.dataset)\n",
    "    num_batches = len(train_loader)\n",
    "    model.train()  # 将模型设置为训练模式\n",
    "    train_loss, train_correct = 0, 0\n",
    "    for batch_idx, (X, y) in enumerate(train_loader):\n",
    "        pred = model(X)\n",
    "        y = y.to(pred.device)\n",
    "        loss = loss_fn(pred, y)\n",
    "        # 梯度清零， 反向传播，更新网络参数\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # 记录损失与正确率\n",
    "        train_loss += loss.item()\n",
    "        train_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        # 每 100批输出一次\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(X), size,\n",
    "                100. * batch_idx / num_batches, loss.item()))\n",
    "    return train_loss / num_batches, train_correct / size\n",
    "# 测试epoch\n",
    "\n",
    "\n",
    "def val_epoch(model, val_loader, loss_fn):\n",
    "    size = len(val_loader.dataset)\n",
    "    num_batches = len(val_loader)\n",
    "    model.eval()  # 设为评估模式\n",
    "    test_loss, test_correct = 0, 0\n",
    "    # 不记录梯度，节省内存\n",
    "    with torch.no_grad():\n",
    "        for X, y in val_loader:\n",
    "            pred = model(X)\n",
    "            y = y.to(pred.device)\n",
    "            loss = loss_fn(pred, y)\n",
    "            test_loss += loss.item()\n",
    "            test_correct += (pred.argmax(1) ==\n",
    "                             y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    print('\\nVal set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, test_correct, size, 100. * test_correct / size))\n",
    "    return test_loss, test_correct / size\n",
    "\n",
    "\n",
    "# 分类问题使用交叉熵作为损失函数\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# 使用随机梯度下降法更新\n",
    "trainer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "# 使用DP模式训练\n",
    "net = nn.DataParallel(net)\n",
    "# 训练轮数\n",
    "num_epochs = 25\n",
    "# 加载数据集\n",
    "train_iter, val_iter, test_data, _ = load_data_fashion_mnist(256)\n",
    "# 记录损失和正确率\n",
    "train_loss, train_accuracy = [], []\n",
    "val_loss, val_accuracy = [], []\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    print(f\"Epoch {epoch}\\n-------------------------------\")\n",
    "    a, b = train_epoch(net, train_iter, trainer, loss_fn, epoch)\n",
    "    train_loss.append(a)\n",
    "    train_accuracy.append(b)\n",
    "    c, d = val_epoch(net, val_iter, loss_fn)\n",
    "    val_loss.append(c)\n",
    "    val_accuracy.append(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.asarray(range(num_epochs))\n",
    "xx = np.column_stack((x, x))\n",
    "y1 = np.column_stack((train_loss, val_loss))\n",
    "y2 = np.column_stack((train_accuracy, val_accuracy))\n",
    "viz.line(y1, xx, win='Loss',\n",
    "         opts=dict(legend=['train_loss',  'val_loss'], xlabel='epoch',\n",
    "                   ylabel='loss', title='Loss',\n",
    "                   markers=True, markersize=8))\n",
    "viz.line(y2, xx, win='Accuracy',\n",
    "         opts=dict(legend=['train_acc',  'val_acc'], xlabel='epoch',\n",
    "                   ylabel='Acc', title='Accuracy',\n",
    "                   markers=True, markersize=8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "def test_model(model, test_X, test_y):\n",
    "    model.eval()\n",
    "    output = model(test_X)\n",
    "    pre_lab = torch.argmax(output,1)\n",
    "    test_y = test_y.cpu().numpy()\n",
    "    pre_lab = pre_lab.cpu().numpy()\n",
    "    acc = accuracy_score(test_y,pre_lab)\n",
    "    print(\"在测试集上的预测精度为:\",acc)\n",
    "    conf_mat = confusion_matrix(test_y,pre_lab)\n",
    "    fig = ff.create_annotated_heatmap(z=conf_mat, x=classes, y=classes, \n",
    "                                      annotation_text=np.around(conf_mat, decimals=2) , \n",
    "                                  colorscale='YlGnBu')\n",
    "    fig.update_layout(title ='混淆矩阵')\n",
    "    fig.update_xaxes(side=\"bottom\")\n",
    "    fig.update_yaxes(autorange=\"reversed\")\n",
    "    viz.plotlyplot(fig, win='heatmap')\n",
    "test_data_X = test_data.data.type(torch.FloatTensor) / 255.0\n",
    "test_data_xX= torch.unsqueeze(test_data_X,dim = 1)\n",
    "test_data_y = test_data.targets  ## 测试集的标签\n",
    "test_model(net, test_data_X, test_data_y)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "73e03da126b73bfff3642ec5261d56fa25c444ea595de51041687efaa60dda41"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
